---
# Source: opensearch/templates/poddisruptionbudget.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: "opensearch-cluster-master-pdb"
  labels:
    helm.sh/chart: opensearch-2.1.0
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/instance: opensearch
    app.kubernetes.io/version: "2.0.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: opensearch-cluster-master
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: opensearch
      app.kubernetes.io/instance: opensearch
---
# Source: opensearch/templates/securityconfig.yaml
apiVersion: v1
kind: Secret
metadata:
  name: opensearch-cluster-master-securityconfig
  namespace: opensearch
  labels:
    helm.sh/chart: opensearch-2.1.0
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/instance: opensearch
    app.kubernetes.io/version: "2.0.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: opensearch-cluster-master
type: Opaque
stringData:
  config.yml: |
    ---
    _meta:
      type: "config"
      config_version: 2
    
    config:
      dynamic:
        http:
          anonymous_auth_enabled: false
        authc:
          internal_auth:
            order: 0
            description: "HTTP basic authentication using the internal user database"
            http_enabled: true
            transport_enabled: true
            http_authenticator:
              type: basic
              challenge: false
            authentication_backend:
              type: internal
          ldap_auth:
            order: 1
            description: "Authenticate using LDAP"
            http_enabled: true
            transport_enabled: true
            http_authenticator:
              type: basic
              challenge: false
            authentication_backend:
              type: ldap
              config:
                enable_ssl: false
                enable_start_tls: false
                enable_ssl_client_auth: false
                verify_hostnames: true
                hosts:
                - ipa1.ls.lsst.org:389
                - ipa2.ls.lsst.org:389
                bind_dn: uid=svc_graylog,cn=users,cn=accounts,dc=lsst,dc=cloud
                password: Z6soX5mdMlyXI9
                userbase: cn=users,cn=accounts,dc=lsst,dc=cloud
                usersearch: (cn={0})
                username_attribute: cn
    
        authz:
          ldap_roles:
            description: "Authorize using LDAP"
            http_enabled: true
            transport_enabled: true
            authorization_backend:
              type: ldap
              config:
                enable_ssl: false
                enable_start_tls: false
                enable_ssl_client_auth: false
                verify_hostnames: true
                hosts:
                - ipa1.ls.lsst.org:389
                - ipa2.ls.lsst.org:389
                bind_dn: uid=svc_graylog,cn=users,cn=accounts,dc=lsst,dc=cloud
                password: Z6soX5mdMlyXI9
                userbase: cn=users,cn=accounts,dc=lsst,dc=cloud
                usersearch: (cn={0})
                username_attribute: cn
                skip_users:
                  - admin
                  - kibanaserver
                rolebase: cn=groups,cn=accounts,dc=lsst,dc=cloud
                rolesearch: (uniqueMember={0})
                userroleattribute: null
                userrolename: disabled
                rolename: cn
                resolve_nested_roles: false
  internal_users.yml: |
    ---
    # This is the internal user database
    # The hash value is a bcrypt hash and can be generated with plugin/tools/hash.sh
    
    _meta:
      type: "internalusers"
      config_version: 2
    
    admin:
      hash: "$2a$12$VcCDgh2NDk07JGN0rjGbM.Ad41qVR/YFJcgHp0UGns5JDymv..TOG"
      reserved: true
      backend_roles:
      - "admin"
      description: "Admin user"
    
    kibanaserver:
      hash: "$2a$12$4AcgAt3xwOWadA5s5blL6ev39OXDNhmOesEoo33eZtrq2N0YrU3H."
      reserved: true
      description: "Kibanaserver user"
  roles_mapping.yml: |
    ---
    _meta:
      type: "rolesmapping"
      config_version: 2
    
    all_access:
      reserved: false
      backend_roles:
      - "admin"
      - "Administrator"
      description: "Maps admin to all_access"
    
    own_index:
      reserved: false
      users:
      - "*"
      description: "Allow full access to an index named like the username"
    
    kibana_user:
      reserved: false
      backend_roles:
      - "kibanauser"
      - "Readers"
      description: "Maps kibanauser to kibana_user"
    
    readall:
      reserved: false
      backend_roles:
      - "readall"
      - "Readers"
    
    manage_snapshots:
      reserved: false
      backend_roles:
      - "snapshotrestore"
      - "Readers"
    
    kibana_server:
      reserved: true
      users:
      - "kibanaserver"
---
# Source: opensearch/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: opensearch-cluster-master-config
  labels:
    helm.sh/chart: opensearch-2.1.0
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/instance: opensearch
    app.kubernetes.io/version: "2.0.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: opensearch-cluster-master
data:
  opensearch.yml: |
    cluster.name: opensearch-cluster
    # Bind to all interfaces because we don't know what IP address Docker will assign to us.
    network.host: 0.0.0.0
    # Setting network.host to a non-loopback address enables the annoying bootstrap checks. "Single-node" mode disables them again.
    # discovery.type: single-node
    # Start OpenSearch Security Demo Configuration
    # WARNING: revise all the lines below before you go into production
    plugins:
      security:
        ssl:
          transport:
            pemcert_filepath: esnode.pem
            pemkey_filepath: esnode-key.pem
            pemtrustedcas_filepath: root-ca.pem
            enforce_hostname_verification: false
          http:
            enabled: true
            pemcert_filepath: esnode.pem
            pemkey_filepath: esnode-key.pem
            pemtrustedcas_filepath: root-ca.pem
        allow_unsafe_democertificates: true
        allow_default_init_securityindex: true
        authcz:
          admin_dn:
            - CN=kirk,OU=client,O=client,L=test,C=de
        audit.type: internal_opensearch
        enable_snapshot_restore_privilege: true
        check_snapshot_restore_write_privileges: true
        restapi:
          roles_enabled: ["all_access", "security_rest_api_access"]
        system_indices:
          enabled: true
          indices:
            [
              ".opendistro-alerting-config",
              ".opendistro-alerting-alert*",
              ".opendistro-anomaly-results*",
              ".opendistro-anomaly-detector*",
              ".opendistro-anomaly-checkpoints",
              ".opendistro-anomaly-detection-state",
              ".opendistro-reports-*",
              ".opendistro-notifications-*",
              ".opendistro-notebooks",
              ".opendistro-asynchronous-search-response*",
            ]
    ######## End OpenSearch Security Demo Configuration ########
---
# Source: opensearch/templates/service.yaml
kind: Service
apiVersion: v1
metadata:
  name: opensearch-cluster-master
  labels:
    helm.sh/chart: opensearch-2.1.0
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/instance: opensearch
    app.kubernetes.io/version: "2.0.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: opensearch-cluster-master
  annotations:
    {}
spec:
  type: LoadBalancer
  selector:
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/instance: opensearch
  ports:
  - name: http
    protocol: TCP
    port: 9200
  - name: transport
    protocol: TCP
    port: 9300
  loadBalancerIP: 139.229.134.153
---
# Source: opensearch/templates/service.yaml
kind: Service
apiVersion: v1
metadata:
  name: opensearch-cluster-master-headless
  labels:
    helm.sh/chart: opensearch-2.1.0
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/instance: opensearch
    app.kubernetes.io/version: "2.0.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: opensearch-cluster-master
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  clusterIP: None # This is needed for statefulset hostnames like opensearch-0 to resolve
  # Create endpoints also if the related pod isn't ready
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/instance: opensearch
  ports:
  - name: http
    port: 9200
  - name: transport
    port: 9300
---
# Source: opensearch/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: opensearch-cluster-master
  labels:
    helm.sh/chart: opensearch-2.1.0
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/instance: opensearch
    app.kubernetes.io/version: "2.0.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: opensearch-cluster-master
  annotations:
    majorVersion: "2"
spec:
  serviceName: opensearch-cluster-master-headless
  selector:
    matchLabels:
      app.kubernetes.io/name: opensearch
      app.kubernetes.io/instance: opensearch
  replicas: 3
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  volumeClaimTemplates:
  - metadata:
      name: opensearch-cluster-master
    spec:
      accessModes:
      - "ReadWriteOnce"
      resources:
        requests:
          storage: "100Gi"
  template:
    metadata:
      name: "opensearch-cluster-master"
      labels:
        helm.sh/chart: opensearch-2.1.0
        app.kubernetes.io/name: opensearch
        app.kubernetes.io/instance: opensearch
        app.kubernetes.io/version: "2.0.1"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: opensearch-cluster-master
      annotations:
        configchecksum: eda023cc5cee44018b6b4985c074bfdbbcd9228f490a3e4fc8d71b2c4bc29a8
        securityconfigchecksum: 03628896e707d5122a15c0da24ed9de62e07898a35ea3c4058a297c80e540c2
    spec:
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      serviceAccountName: ""
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchExpressions:
                - key: app.kubernetes.io/instance
                  operator: In
                  values:
                  - opensearch
                - key: app.kubernetes.io/name
                  operator: In
                  values:
                  - opensearch
      terminationGracePeriodSeconds: 120
      volumes:
      - name: config
        configMap:
          name: opensearch-cluster-master-config
      - name: security-config-data
        secret:
          secretName: opensearch-cluster-master-securityconfig
      enableServiceLinks: true
      initContainers:
      - name: fsgroup-volume
        image: "busybox:latest"
        command: ['sh', '-c']
        args:
          - 'chown -R 1000:1000 /usr/share/opensearch/data'
        securityContext:
          runAsUser: 0
        resources: 
           
          {}
        volumeMounts:
          - name: "opensearch-cluster-master"
            mountPath: /usr/share/opensearch/data

      containers:
      - name: "opensearch"
        securityContext:
          capabilities:
            drop:
            - ALL
          runAsNonRoot: true
          runAsUser: 1000
        image: "opensearchproject/opensearch:2.0.1"
        imagePullPolicy: "IfNotPresent"
        ports:
        - name: http
          containerPort: 9200
        - name: transport
          containerPort: 9300
        resources:
          requests:
            cpu: 1000m
            memory: 100Mi
        env:
        - name: node.name
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: cluster.initial_master_nodes
          value: "opensearch-cluster-master-0,opensearch-cluster-master-1,opensearch-cluster-master-2,"
        - name: discovery.seed_hosts
          value: "opensearch-cluster-master-headless"
        - name: cluster.name
          value: "opensearch-cluster"
        - name: network.host
          value: "0.0.0.0"
        - name: OPENSEARCH_JAVA_OPTS
          value: "-Xmx512M -Xms512M"
        - name: node.roles
          value: "master,ingest,data,remote_cluster_client,"
        volumeMounts:
        - name: "opensearch-cluster-master"
          mountPath: /usr/share/opensearch/data
        - mountPath: /usr/share/opensearch/plugins/opensearch-security/securityconfig
          name: security-config-data
        - name: config
          mountPath: /usr/share/opensearch/config/opensearch.yml
          subPath: opensearch.yml
---
# Source: opensearch/templates/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: opensearch-cluster-master
  labels:
    helm.sh/chart: opensearch-2.1.0
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/instance: opensearch
    app.kubernetes.io/version: "2.0.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: opensearch-cluster-master
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/ssl-passthrough: "true"
spec:
  tls:
    - hosts:
        - it-opensearch.dev.lsst.org
      secretName: it-opensearch-tls
  rules:
    - host: "it-opensearch.dev.lsst.org"
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: opensearch-cluster-master
                port:
                  number: 9200
