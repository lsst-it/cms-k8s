---
# Source: grafana/templates/podsecuritypolicy.yaml
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: grafana
  namespace: it-monitoring
  labels:
    helm.sh/chart: grafana-5.6.12
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: grafana
    app.kubernetes.io/version: "7.2.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    seccomp.security.alpha.kubernetes.io/allowedProfileNames: 'docker/default'
    seccomp.security.alpha.kubernetes.io/defaultProfileName:  'docker/default'
    apparmor.security.beta.kubernetes.io/allowedProfileNames: 'runtime/default'
    apparmor.security.beta.kubernetes.io/defaultProfileName:  'runtime/default'
spec:
  privileged: false
  allowPrivilegeEscalation: false
  requiredDropCapabilities:
    # Default set from Docker, without DAC_OVERRIDE or CHOWN
    - FOWNER
    - FSETID
    - KILL
    - SETGID
    - SETUID
    - SETPCAP
    - NET_BIND_SERVICE
    - NET_RAW
    - SYS_CHROOT
    - MKNOD
    - AUDIT_WRITE
    - SETFCAP
  volumes:
    - 'configMap'
    - 'emptyDir'
    - 'projected'
    - 'secret'
    - 'downwardAPI'
    - 'persistentVolumeClaim'
  hostNetwork: false
  hostIPC: false
  hostPID: false
  runAsUser:
    rule: 'RunAsAny'
  seLinux:
    rule: 'RunAsAny'
  supplementalGroups:
    rule: 'RunAsAny'
  fsGroup:
    rule: 'RunAsAny'
  readOnlyRootFilesystem: false
---
# Source: grafana/templates/tests/test-podsecuritypolicy.yaml
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: grafana-test
  namespace: it-monitoring
  labels:
    helm.sh/chart: grafana-5.6.12
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: grafana
    app.kubernetes.io/version: "7.2.0"
    app.kubernetes.io/managed-by: Helm
spec:
  allowPrivilegeEscalation: true
  privileged: false
  hostNetwork: false
  hostIPC: false
  hostPID: false
  fsGroup:
    rule: RunAsAny
  seLinux:
    rule: RunAsAny
  supplementalGroups:
    rule: RunAsAny
  runAsUser:
    rule: RunAsAny
  volumes:
  - configMap
  - downwardAPI
  - emptyDir
  - projected
  - secret
---
# Source: grafana/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    helm.sh/chart: grafana-5.6.12
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: grafana
    app.kubernetes.io/version: "7.2.0"
    app.kubernetes.io/managed-by: Helm
  name: grafana
  namespace: it-monitoring
---
# Source: grafana/templates/tests/test-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    helm.sh/chart: grafana-5.6.12
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: grafana
    app.kubernetes.io/version: "7.2.0"
    app.kubernetes.io/managed-by: Helm
  name: grafana-test
  namespace: it-monitoring
---
# Source: grafana/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana
  namespace: it-monitoring
  labels:
    helm.sh/chart: grafana-5.6.12
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: grafana
    app.kubernetes.io/version: "7.2.0"
    app.kubernetes.io/managed-by: Helm
data:
  grafana.ini: |
    [analytics]
    check_for_updates = true
    [auth.ldap]
    allow_sign_up = true
    config_file = /etc/grafana/ldap.toml
    enabled = true
    [grafana_net]
    url = https://grafana.net
    [log]
    mode = console
    [paths]
    data = /var/lib/grafana/data
    logs = /var/log/grafana
    plugins = /var/lib/grafana/plugins
    provisioning = /etc/grafana/provisioning

  grafana.yaml: |
    apiVersion: 1
    datasources:
    - access: proxy
      database: grafana
      isDefault: true
      name: IT InfluxDB
      password: ${INFLUXDB_PASSWORD}
      type: influxdb
      url: http://influxdb-0.influxdb.it-influxdb.svc.cluster.local:8086
      user: ${INFLUXDB_USERNAME}
    - access: proxy
      database: _internal
      isDefault: false
      name: IT InfluxDB internal
      password: ${INFLUXDB_PASSWORD}
      type: influxdb
      url: http://influxdb-0.influxdb.it-influxdb.svc.cluster.local:8086
      user: ${INFLUXDB_USERNAME}
  enabled: |
    false
  label: |
    grafana_notifier
  searchNamespace: |
    null
---
# Source: grafana/templates/tests/test-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-test
  namespace: it-monitoring
  labels:
    helm.sh/chart: grafana-5.6.12
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: grafana
    app.kubernetes.io/version: "7.2.0"
    app.kubernetes.io/managed-by: Helm
data:
  run.sh: |-
    @test "Test Health" {
      url="http://grafana/api/health"

      code=$(wget --server-response --spider --timeout 10 --tries 1 ${url} 2>&1 | awk '/^  HTTP/{print $2}')
      [ "$code" == "200" ]
    }
---
# Source: grafana/templates/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    helm.sh/chart: grafana-5.6.12
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: grafana
    app.kubernetes.io/version: "7.2.0"
    app.kubernetes.io/managed-by: Helm
  name: grafana-clusterrole
rules: []
---
# Source: grafana/templates/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: grafana-clusterrolebinding
  labels:
    helm.sh/chart: grafana-5.6.12
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: grafana
    app.kubernetes.io/version: "7.2.0"
    app.kubernetes.io/managed-by: Helm
subjects:
  - kind: ServiceAccount
    name: grafana
    namespace: it-monitoring
roleRef:
  kind: ClusterRole
  name: grafana-clusterrole
  apiGroup: rbac.authorization.k8s.io
---
# Source: grafana/templates/role.yaml
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: Role
metadata:
  name: grafana
  namespace: it-monitoring
  labels:
    helm.sh/chart: grafana-5.6.12
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: grafana
    app.kubernetes.io/version: "7.2.0"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:      ['extensions']
  resources:      ['podsecuritypolicies']
  verbs:          ['use']
  resourceNames:  [grafana]
---
# Source: grafana/templates/tests/test-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: grafana-test
  namespace: it-monitoring
  labels:
    helm.sh/chart: grafana-5.6.12
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: grafana
    app.kubernetes.io/version: "7.2.0"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:      ['policy']
  resources:      ['podsecuritypolicies']
  verbs:          ['use']
  resourceNames:  [grafana-test]
---
# Source: grafana/templates/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: grafana
  namespace: it-monitoring
  labels:
    helm.sh/chart: grafana-5.6.12
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: grafana
    app.kubernetes.io/version: "7.2.0"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: grafana
subjects:
- kind: ServiceAccount
  name: grafana
  namespace: it-monitoring
---
# Source: grafana/templates/tests/test-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: grafana-test
  namespace: it-monitoring
  labels:
    helm.sh/chart: grafana-5.6.12
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: grafana
    app.kubernetes.io/version: "7.2.0"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: grafana-test
subjects:
- kind: ServiceAccount
  name: grafana-test
  namespace: it-monitoring
---
# Source: grafana/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: it-monitoring
  labels:
    helm.sh/chart: grafana-5.6.12
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: grafana
    app.kubernetes.io/version: "7.2.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - name: service
      port: 80
      protocol: TCP
      targetPort: 3000

  selector:
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: grafana
---
# Source: grafana/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: it-monitoring
  labels:
    helm.sh/chart: grafana-5.6.12
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: grafana
    app.kubernetes.io/version: "7.2.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/name: grafana
      app.kubernetes.io/instance: grafana
  strategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: grafana
        app.kubernetes.io/instance: grafana
      annotations:
        checksum/config: 529b93ff1b1fe84f25ebd02b6edaff35b6435f6603bb479ebe0c1eea1f719f5e
        checksum/dashboards-json-config: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
        checksum/sc-dashboard-provider-config: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
    spec:
      
      serviceAccountName: grafana
      securityContext:
        fsGroup: 472
        runAsGroup: 472
        runAsUser: 472
      containers:
        - name: grafana
          image: "grafana/grafana:7.2.0"
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: config
              mountPath: "/etc/grafana/grafana.ini"
              subPath: grafana.ini
            - name: ldap
              mountPath: "/etc/grafana/ldap.toml"
              subPath: ldap.toml
            - name: storage
              mountPath: "/var/lib/grafana"
            - name: config
              mountPath: "/etc/grafana/provisioning/datasources/datasources.yaml"
              subPath: datasources.yaml
            - name: config
              mountPath: "/etc/grafana/provisioning/notifiers/notifiers.yaml"
              subPath: notifiers.yaml
          ports:
            - name: service
              containerPort: 80
              protocol: TCP
            - name: grafana
              containerPort: 3000
              protocol: TCP
          env:
            - name: GF_SECURITY_ADMIN_USER
              valueFrom:
                secretKeyRef:
                  name: grafana-credentials
                  key: admin-user
            - name: GF_SECURITY_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: grafana-credentials
                  key: admin-password
            - name: "INFLUXDB_PASSWORD"
              valueFrom:
                secretKeyRef:
                  key: admin-password
                  name: grafana-credentials
            - name: "INFLUXDB_USERNAME"
              valueFrom:
                secretKeyRef:
                  key: admin-user
                  name: grafana-credentials
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /api/health
              port: 3000
            initialDelaySeconds: 60
            timeoutSeconds: 30
          readinessProbe:
            httpGet:
              path: /api/health
              port: 3000
          resources:
            limits:
              cpu: 100m
              memory: 128Mi
            requests:
              cpu: 100m
              memory: 128Mi
      volumes:
        - name: config
          configMap:
            name: grafana
        - name: ldap
          secret:
            secretName: ldap-secret
            items:
              - key: ldap-toml
                path: ldap.toml
        - name: storage
          emptyDir: {}
---
# Source: grafana/templates/ingress.yaml
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: grafana
  namespace: it-monitoring
  labels:
    helm.sh/chart: grafana-5.6.12
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: grafana
    app.kubernetes.io/version: "7.2.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt"
    kubernetes.io/ingress.class: "nginx"
    nginx.ingress.kubernetes.io/ssl-passthrough: "true"
spec:
  tls:
    - hosts:
      - it-grafana.ls.lsst.org
      secretName: grafana-tls
  rules:
    - host: it-grafana.ls.lsst.org
      http:
        paths:

          - path: /
            backend:
              serviceName: grafana
              servicePort: 80
---
# Source: grafana/templates/tests/test.yaml
apiVersion: v1
kind: Pod
metadata:
  name: grafana-test
  labels:
    helm.sh/chart: grafana-5.6.12
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: grafana
    app.kubernetes.io/version: "7.2.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test-success
  namespace: it-monitoring
spec:
  serviceAccountName: grafana-test
  containers:
    - name: grafana-test
      image: "bats/bats:v1.1.0"
      imagePullPolicy: "IfNotPresent"
      command: ["/opt/bats/bin/bats", "-t", "/tests/run.sh"]
      volumeMounts:
        - mountPath: /tests
          name: tests
          readOnly: true
  volumes:
  - name: tests
    configMap:
      name: grafana-test
  restartPolicy: Never
